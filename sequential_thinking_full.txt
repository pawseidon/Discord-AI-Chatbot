import os
import json
import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple, Union
import time
import re
import random

# Import for LLM fallback
from bot_utilities.ai_utils import get_ai_provider, generate_response
from bot_utilities.fallback_utils import record_llm_success, cache_successful_response, get_fallback_response

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('sequential_thinking')

class SequentialThinking:
    """
    Implements sequential thinking capabilities directly using the LLM
    
    Based on research in "Fine-Tuning Large Language Models with Sequential Instructions"
    (https://arxiv.org/html/2403.07794v1)
    """
    
    def __init__(self, llm_provider=None):
        """
        Initialize the sequential thinking module.
        
        Args:
            llm_provider: A language model provider instance that has an async call method
        """
        self.llm_provider = llm_provider
        self.thinking_style_templates = {
            "sequential": {
                "prompt": """You are an AI assistant tasked with solving problems using sequential thinking.
                
I'll present you with a problem, and I'd like you to solve it by breaking it down into clear, logical steps.

For this problem: "{problem}"

Think through this step by step:
1. First, understand what's being asked
2. Break down the problem into manageable parts
3. Address each part in a logical sequence
4. Be precise and thorough in your analysis
5. Check your reasoning for errors or inconsistencies
6. Finally, provide ONLY your answer in a natural, conversational way without mentioning your step-by-step process

Context information: {context}

Please solve this problem by analyzing it sequentially. After your thorough analysis, respond only with your final answer in a natural, conversational tone that directly addresses what was asked.
""",
                "output_parser": self._parse_sequential_output
            },
            "list": {
                "prompt": """You are an AI assistant tasked with solving problems using list-based thinking.
                
I'll present you with a problem, and I'd like you to solve it by breaking it down into a list of clear, logical points.

For this problem: "{problem}"

Think through this by creating a clear list of points:
- First, understand what's being asked
- Break down the problem into a list of key considerations
- Address each point thoroughly
- Be precise and thorough in your analysis
- Check your list for completeness and accuracy

Context information: {context}

Please solve this problem by analyzing it as a structured list. Show your thinking as you work through each point.
""",
                "output_parser": self._parse_list_output
            },
            "cot": {
                "prompt": """You are an AI assistant tasked with solving problems using chain-of-thought reasoning.

I'll present you with a problem, and I'd like you to solve it by working through a chain of logical reasoning.

For this problem: "{problem}"

Think through this chain of thought step by step. After your detailed analysis, provide a clear, concise final answer that directly addresses the question without mentioning your thinking process. Your response should be conversational and natural, as if you're simply explaining the topic to the person asking.

1. First, understand what's being asked
2. Identify the key variables and relationships
3. Reason step by step to derive the answer
4. Be explicit about your logical connections
5. Check your reasoning carefully
6. Finally, provide ONLY the answer in a natural, conversational way without mentioning your step-by-step process

Context information: {context}

Please solve this problem by tracing through a clear chain of thought, then give only your final answer in a natural, conversational tone.
""",
                "output_parser": self._parse_cot_output
            },
            "cov": {
                "prompt": """You are an AI assistant tasked with solving problems using chain-of-verification reasoning.

I'll present you with a problem, and I'd like you to solve it by working through a chain of logical reasoning, 
but with an additional verification step to catch any errors or inconsistencies.

For this problem: "{problem}"

Think through this chain of verification process:
1. First, understand what's being asked
2. Identify the key variables and relationships
3. Reason step by step to derive an initial answer
4. VERIFICATION: Check each step of your reasoning for:
   - Factual accuracy
   - Logical coherence
   - Missing information
   - Potential biases
   - Alternative interpretations
5. Revise your answer if verification reveals issues
6. Provide your final, verified answer

Context information: {context}

Please solve this problem by using a chain-of-verification approach. Show your reasoning explicitly, 
including the verification steps where you double-check your work.
""",
                "output_parser": self._parse_cov_output
            },
            "got": {
                "prompt": """You are an AI assistant tasked with solving problems using Graph-of-Thought reasoning.

I'll present you with a problem, and I'd like you to solve it by creating a mental graph of connected thoughts 
and concepts rather than a strictly linear sequence.

For this problem: "{problem}"

Apply Graph-of-Thought reasoning as follows:
1. First, understand what's being asked
2. Identify key concepts and their relationships (nodes in your thought graph)
3. Explore multiple thought branches in parallel where relevant
4. Create connections between related thoughts
5. Identify knowledge gaps and bridge them
6. Converge diverse thought paths into a cohesive solution
7. Organize your final answer based on the most important insights

Context information: {context}

Please solve this problem by visualizing and working through a graph of interconnected thoughts. 
Show your thinking as you explore different branches of reasoning, making connections between concepts,
and converging on a solution. Label different thought branches clearly.
""",
                "output_parser": self._parse_got_output
            }
        }
        
    async def set_llm_provider(self, provider):
        """
        Set the language model provider
        
        Args:
            provider: The LLM provider to use
        """
        if not provider:
            # Try to get an AI provider if not provided
            try:
                from bot_utilities.ai_utils import get_ai_provider
                provider = await get_ai_provider()
                print("Obtained AI provider automatically")
            except Exception as e:
                print(f"Failed to get AI provider: {e}")
                provider = None  # We'll use fallbacks if no provider
        
        self.llm_provider = provider
        
    async def _call_llm(self, prompt, model=None, temperature=0.7, max_tokens=2000, timeout=60, include_thinking=False):
        """
        Call the LLM with a prompt
        
        Args:
            prompt: The prompt to send
            model: Optional model override
            temperature: Temperature setting for randomness
            max_tokens: Max tokens to generate
            timeout: Timeout in seconds
            include_thinking: Whether to include thinking process in output
            
        Returns:
            str: The LLM response
        """
        # Normalize prompt to lowercase for pattern matching
        prompt_lower = prompt.lower()
        
        # Shorter timeout for complex topics to prevent hanging
        if any(complex_word in prompt_lower for complex_word in ["complex", "detailed", "comprehensive", "thorough", "in-depth"]):
            if timeout > 30:  # Only reduce if it's set higher
                timeout = 30
                print(f"Reduced timeout to {timeout}s for complex query")

        try:
            # Try to get a response from the LLM
            if self.llm_provider:
                # Use the provider to get a response
                try:
                    # Set a timeout to prevent hanging
                    async with asyncio.timeout(timeout):
                        response = await self.llm_provider.async_call(
                            prompt=prompt,
                            temperature=temperature,
                            max_tokens=max_tokens
                        )
                        # Record success for monitoring
                        record_llm_success()
                        # Cache this successful response
                        cache_successful_response(prompt, response)
                        
                        return response
                except asyncio.TimeoutError:
                    print(f"Timeout after {timeout}s while waiting for LLM response")
                    # Fall back to domain-specific response
                    return self._get_domain_specific_fallback(prompt_lower)
                except Exception as e:
                    print(f"Error calling LLM: {e}")
                    # Try to get fallback from cache
                    fallback = get_fallback_response(prompt)
                    if fallback:
                        return fallback
                    
                    # Fall back to domain-specific response
                    return self._get_domain_specific_fallback(prompt_lower)
            else:
                print("No LLM provider available")
                # Try to get fallback from cache
                fallback = get_fallback_response(prompt)
                if fallback:
                    return fallback
                
                # Fall back to domain-specific response
                return self._get_domain_specific_fallback(prompt_lower)
                
        except Exception as e:
            print(f"Critical error in _call_llm: {e}")
            # Try to get fallback from cache
            fallback = get_fallback_response(prompt)
            if fallback:
                return fallback
            
            # Fall back to domain-specific response as final resort
            return self._get_domain_specific_fallback(prompt_lower)

    def _get_tech_fallback_response(self, prompt_lower):
        """Generate a technology domain fallback response"""
        if "python" in prompt_lower:
            return """
Python is a high-level, interpreted programming language known for its readability and versatility. It supports multiple programming paradigms including procedural, object-oriented, and functional programming.

Key features include dynamic typing, automatic memory management, and a comprehensive standard library. Python is widely used in web development, data science, AI/ML, automation, and many other domains.

Popular frameworks and libraries include Django and Flask for web development, NumPy and Pandas for data analysis, TensorFlow and PyTorch for machine learning, and many others that make Python extremely powerful for diverse applications.
"""
        elif "javascript" in prompt_lower:
            return """
JavaScript is a versatile scripting language primarily used for creating interactive web pages. It's an essential component of web development alongside HTML and CSS.

Key features include its event-driven programming model, asynchronous capabilities, and support for functional and object-oriented programming paradigms. Modern JavaScript has evolved significantly with ES6+ features like arrow functions, destructuring, and async/await.

The ecosystem includes frameworks like React, Angular, and Vue for frontend development, Node.js for server-side applications, and tools like npm or yarn for package management.
"""
        else:
            return """
Technology is constantly evolving with new programming languages, frameworks, and tools emerging regularly. Software development involves various stages including planning, coding, testing, and deployment.

Modern software practices emphasize concepts like CI/CD (Continuous Integration/Continuous Deployment), infrastructure as code, containerization, and microservices architecture.

Programming paradigms like object-oriented, functional, and reactive programming each offer different approaches to solving computing problems, with languages often supporting multiple paradigms to provide developers flexibility in their approach.
"""

    def _get_science_fallback_response(self, prompt_lower):
        """Generate a science domain fallback response"""
        if "physics" in prompt_lower:
            return """
Physics seeks to understand the fundamental laws governing the universe, from subatomic particles to cosmic structures. Major branches include mechanics, thermodynamics, electromagnetism, relativity, and quantum mechanics.

Key concepts include the conservation of energy, Newton's laws of motion, and Einstein's theories of relativity. Modern physics explores fascinating phenomena like quantum entanglement, the Higgs boson, and the nature of dark matter and dark energy.

Physics provides the foundation for many technological advancements and continues to evolve with new discoveries and theories that challenge our understanding of reality.
"""
        elif "biology" in prompt_lower:
            return """
Biology is the scientific study of life and living organisms. It encompasses diverse subfields including molecular biology, genetics, ecology, evolutionary biology, and physiology.

Key principles include cell theory, evolution by natural selection, gene inheritance, homeostasis, and energy processing. Modern biology has been revolutionized by advances in genomics, CRISPR gene editing, and computational biology.

These developments have profound implications for medicine, agriculture, and our understanding of life's diversity and interconnectedness on Earth.
"""
        else:
            return """
Science is a systematic approach to understanding the natural world through observation, experimentation, and analysis. The scientific method provides a framework for testing hypotheses and developing theories.

Major scientific disciplines include physics, chemistry, biology, astronomy, and earth sciences, each with numerous specialized subfields. Interdisciplinary approaches are increasingly important for addressing complex questions.

Scientific progress continues to expand human knowledge, challenge existing paradigms, and provide the foundation for technological innovation and evidence-based decision making.
"""

    def _get_business_fallback_response(self, prompt_lower):
        """Generate a business domain fallback response"""
        if "investment" in prompt_lower:
            return """
Investment involves allocating resources with the expectation of generating income or profit over time. Common investment vehicles include stocks, bonds, real estate, mutual funds, ETFs, and alternative investments.

Key investment concepts include risk vs. return, diversification, asset allocation, and compound interest. Different investment strategies like value investing, growth investing, and passive index investing suit different goals and risk tolerances.

Successful investing typically requires understanding market fundamentals, having a long-term perspective, and managing psychological biases that can lead to poor decision-making.
"""
        elif "startup" in prompt_lower or "entrepreneur" in prompt_lower:
            return """
Entrepreneurship involves identifying opportunities, developing innovative solutions, and creating new ventures. Successful startups typically solve meaningful problems, have scalable business models, and are led by adaptable founders.

The startup journey includes stages from ideation and validation to scaling and potential exit. Funding sources may include bootstrapping, angel investors, venture capital, crowdfunding, and strategic partnerships.

Key challenges entrepreneurs face include securing resources, building effective teams, managing growth, adapting to market changes, and maintaining work-life balance while pursuing their vision.
"""
        else:
            return """
Business encompasses the activities and organizations involved in the production, distribution, and exchange of goods and services. Successful businesses create value for customers, employees, shareholders, and communities.

Key business concepts include strategic planning, marketing, operations management, financial analysis, and organizational behavior. Modern business practices are being transformed by digitalization, globalization, sustainability concerns, and evolving consumer expectations.

Effective business leadership requires balancing short-term results with long-term vision, managing diverse stakeholder needs, and adapting to changing market conditions and technological developments.
"""

    def _get_arts_fallback_response(self, prompt_lower):
        """Generate an arts and humanities domain fallback response"""
        if "music" in prompt_lower:
            return """
Music is both an art form and cultural activity centered on organized sound. It spans countless genres, traditions, and styles across cultures and throughout history.

Key elements of music include melody, harmony, rhythm, timbre, and texture. Music theory provides frameworks for understanding these elements and their relationships. The creation and performance of music involves various instruments, vocal techniques, composition methods, and production technologies.

Music serves diverse purposes including entertainment, artistic expression, cultural preservation, social bonding, and emotional processing. Its psychological and neurological effects continue to be studied, revealing its profound impact on human experience.
"""
        elif "philosophy" in prompt_lower:
            return """
Philosophy examines fundamental questions about existence, knowledge, ethics, reason, mind, and language. Major branches include metaphysics, epistemology, ethics, logic, and aesthetics.

Historical philosophical traditions span Western philosophy (from Ancient Greek to Continental and Analytic), Eastern philosophy (including Buddhist, Hindu, Chinese, and Islamic thought), and indigenous philosophical systems worldwide.

Philosophical inquiry has shaped human understanding across disciplines including science, politics, law, and art, providing frameworks for critical thinking, ethical reasoning, and examining the nature of reality and human experience.
"""
        else:
            return """
The arts and humanities encompass diverse forms of human expression and cultural study including visual arts, literature, music, theater, philosophy, history, and religion. These disciplines explore creativity, aesthetics, meaning, and values.

Creative works can reflect, critique, or reimagine society while conveying emotional, intellectual, and spiritual dimensions of human experience. Humanities scholarship examines texts, artifacts, and cultural practices to understand their contexts, interpretations, and significance.

Together, arts and humanities foster critical thinking, cultural literacy, empathy, and appreciation for human diversity and creativity across time and cultures.
"""

    def _get_health_fallback_response(self, prompt_lower):
        """Generate a health and medicine domain fallback response"""
        if "nutrition" in prompt_lower or "diet" in prompt_lower:
            return """
Nutrition science studies how food and its components affect health and bodily functions. A balanced diet typically includes proteins, carbohydrates, fats, vitamins, minerals, and water in appropriate amounts.

Dietary needs vary based on age, sex, activity level, health status, and other factors. Evidence-based dietary patterns like Mediterranean, DASH, and plant-focused diets are associated with positive health outcomes for many people.

Nutrition research continues to evolve, with emerging understanding of topics like the gut microbiome, personalized nutrition, food-gene interactions, and the complex relationship between dietary patterns and chronic disease prevention.
"""
        elif "mental health" in prompt_lower or "psychology" in prompt_lower:
            return """
Mental health encompasses emotional, psychological, and social well-being, affecting how we think, feel, act, handle stress, relate to others, and make choices. Mental health exists on a spectrum and can change over time.

Common mental health conditions include depression, anxiety disorders, bipolar disorder, PTSD, and schizophrenia. Treatment approaches include psychotherapy (like CBT, DBT), medication, lifestyle changes, social support, and complementary practices.

Mental health is influenced by biological factors, life experiences, family history, and social determinants. Reducing stigma, increasing access to care, and promoting mental health literacy are important public health goals.
"""
        else:
            return """
Health and medicine encompass the maintenance of physical and mental well-being and the prevention, diagnosis, treatment, and management of disease. Healthcare combines scientific knowledge, clinical expertise, and patient values.

Modern medicine integrates biomedical understanding with recognition of psychological, social, and environmental determinants of health. Evidence-based practice combines research findings with clinical expertise and patient preferences.

Healthcare continues to evolve with advances in medical technology, precision medicine, digital health tools, and increasing emphasis on preventive care, patient-centered approaches, and addressing health disparities.
"""

    def _get_geopolitics_fallback_response(self, prompt_lower):
        """Generate a geopolitics domain fallback response based on regional focus"""
        # East Asia
        if any(term in prompt_lower for term in ["china", "japan", "korea", "taiwan", "hong kong"]):
            return """
East Asian geopolitics involves complex dynamics among major powers like China, Japan, South Korea, and North Korea, alongside Taiwan and Hong Kong. Key issues include territorial disputes in the South and East China Seas, economic competition, historical tensions, nuclear concerns, and balancing relations with the United States.

Regional security architecture includes various bilateral alliances and multilateral forums like ASEAN. Economic integration through trade and investment continues despite political tensions, with organizations like RCEP promoting regional cooperation.

The region's future stability depends on managing nationalism, military buildups, economic interdependence, and great power competition while addressing shared challenges like demographic shifts and technological transformation.
"""
        # Middle East
        elif any(term in prompt_lower for term in ["middle east", "iran", "israel", "palestine", "saudi", "syria", "turkey", "egypt", "iraq"]):
            return """
Middle Eastern geopolitics is shaped by complex intersections of religion, ethnicity, resources, and great power interventions. Key dynamics include the Israeli-Palestinian conflict, Iran-Saudi rivalry, political Islam, and post-Arab Spring transitions.

Energy resources, especially oil and natural gas, remain strategically important despite global energy transitions. Water security and climate adaptation present growing challenges in this predominantly arid region.

Ongoing issues include terrorism, sectarian tensions, refugee crises, and governance challenges, with various external powers pursuing influence through diplomatic, economic, and military means.
"""
        # Africa
        elif any(term in prompt_lower for term in ["africa", "sahel", "ethiopia", "nigeria", "kenya", "south africa", "congo", "sudan"]):
            return """
African geopolitics reflects the continent's immense diversity and evolving position in global affairs. Key dynamics include rapid demographic growth, economic development opportunities, resource competition, governance challenges, and external power engagement.

Regional organizations like the African Union and sub-regional bodies work toward integration and conflict management. China's growing influence through infrastructure investment competes with traditional Western approaches and emerging partnerships.

Security challenges vary by region, from terrorism in the Sahel to maritime security in coastal areas, while climate change impacts threaten agricultural systems and human security across the continent.
"""
        # South Asia
        elif any(term in prompt_lower for term in ["south asia", "india", "pakistan", "bangladesh", "afghanistan", "sri lanka", "nepal"]):
            return """
South Asian geopolitics centers on complex relations among countries with shared cultural and historical ties but significant political differences. Regional dynamics include India's emergence as a major power, Indo-Pakistani tensions, China's growing influence, and Afghanistan's ongoing security challenges.

Economic integration remains limited despite geographic proximity, with SAARC achieving modest results compared to other regional organizations. Cross-border issues include water sharing, terrorism, and migration.

The region faces significant development challenges alongside opportunities, with climate vulnerability, demographic trends, and technological adoption shaping future trajectories.
"""
        # Europe
        elif any(term in prompt_lower for term in ["europe", "eu", "european union", "nato", "russia", "ukraine", "brexit", "germany", "france", "uk"]):
            return """
European geopolitics involves both integration through the European Union and NATO, and tensions with Russia over spheres of influence. Key issues include EU cohesion after Brexit, energy security, migration management, and balancing transatlantic relations.

Russia-West relations remain strained over Ukraine, cyber operations, and competing visions for European security architecture. Europe's economic weight is balanced against fragmented foreign policy and security capabilities.

Future challenges include demographic decline, technological competitiveness, climate policy implementation, and managing internal political divisions while maintaining European values and influence in a multipolar world.
"""
        # Americas
        elif any(term in prompt_lower for term in ["americas", "latin america", "caribbean", "usa", "canada", "mexico", "brazil", "colombia", "venezuela"]):
            return """
Geopolitics in the Americas involves asymmetric relations between the United States and Latin American and Caribbean nations. Regional dynamics include varying approaches to integration, from NAFTA/USMCA to MERCOSUR, alongside political diversity from liberal democracies to authoritarian systems.

Key issues include migration flows, narcotics trafficking, resource development, environmental protection, and external influences from China and Russia. Indigenous rights movements and transitional justice shape domestic politics across the region.

Economic inequality, institutional stability, and public security remain significant challenges, while the region's abundant resources, young populations, and cultural dynamism present opportunities for sustainable development.
"""
        # Global issues
        elif any(term in prompt_lower for term in ["global", "international order", "un", "united nations", "multilateral", "climate change", "trade", "human rights"]):
            return """
Global geopolitics involves interactions between state and non-state actors within evolving international systems and norms. Current dynamics include a shift toward multipolarity, tensions between globalization and nationalism, and debates over liberal international order.

International institutions face reform pressures amid changing power distributions, while transnational challenges like climate change, pandemic prevention, and digital governance require collective action despite competitive dynamics.

Core debates include balancing sovereignty with global governance, addressing historical injustices while building future cooperation, and managing technological disruption across military, economic, and social domains.
"""
        # Default geopolitical response
        else:
            return """
Geopolitics examines how geography, politics, history, economics, and culture influence international relations and state behavior. Major concepts include balance of power, spheres of influence, resource competition, and strategic chokepoints.

Contemporary geopolitical dynamics involve great power competition, regional integration and fragmentation, non-state actors, transnational challenges like climate change, and technological disruption. International institutions and norms provide frameworks for cooperation and conflict management.

Understanding geopolitics requires analyzing complex interactions between domestic politics, international systems, historical context, and diverse factors shaping state interests and capabilities.
"""

    def _get_religion_philosophy_fallback_response(self, prompt_lower):
        """Generate a religion and philosophy domain fallback response"""
        # Religious traditions
        if any(term in prompt_lower for term in ["christianity", "islam", "judaism", "hinduism", "buddhism", "sikhism", "taoism", "shinto"]):
            return """
The world's major religious traditions offer diverse perspectives on ultimate reality, human purpose, and ethical living. Each tradition includes various denominations, sects, and schools with distinct interpretations of core texts and practices.

Religious communities balance preservation of tradition with adaptation to contemporary contexts. Sacred texts, rituals, ethical systems, and community structures provide frameworks for meaning and identity across cultures.

Interfaith dialogue seeks understanding across religious boundaries, while secularization and religious revitalization occur simultaneously in different contexts. Religion continues to influence politics, ethics, and culture alongside scientific and technological development.
"""
        # Philosophy branches
        elif any(term in prompt_lower for term in ["ethics", "metaphysics", "epistemology", "logic", "aesthetics", "political philosophy", "philosophy of mind", "existentialism"]):
            return """
Philosophical inquiry examines fundamental questions about reality, knowledge, values, and reason through systematic analysis and argument. Major branches include metaphysics (nature of reality), epistemology (theory of knowledge), ethics (moral principles), logic (reasoning methods), and aesthetics (beauty and art).

Western philosophical traditions span Ancient Greek thought through medieval scholasticism to modern and contemporary approaches. Non-Western traditions include rich philosophical systems from Chinese, Indian, African, and Indigenous perspectives.

Applied philosophy addresses practical questions in fields like bioethics, environmental ethics, AI ethics, and social justice, connecting abstract reasoning with concrete problems facing humanity.
"""
        # Default philosophy and religion response
        else:
            return """
Philosophy and religion address fundamental questions about existence, meaning, ethics, and reality, though with different methodological approaches. Both examine human experience and values across cultural and historical contexts.

Religious traditions typically involve beliefs about transcendent reality, practices of worship or contemplation, ethical frameworks, and community structures. Philosophical approaches emphasize systematic reasoning, conceptual analysis, and argumentative clarity.

The relationship between faith and reason, religion and science, and individual conscience and tradition continues to evolve, with implications for personal identity, social cohesion, and human understanding of our place in the universe.
"""

    def _get_environmental_fallback_response(self, prompt_lower):
        """Generate an environmental domain fallback response"""
        # Climate focus
        if any(term in prompt_lower for term in ["climate change", "global warming", "carbon", "greenhouse", "emissions"]):
            return """
Climate change involves long-term alterations in temperature, precipitation, and weather patterns due to increased greenhouse gas concentrations. Scientific evidence shows human activities, particularly fossil fuel combustion and land use changes, are the primary drivers of current warming trends.

Impacts include rising sea levels, intensified extreme weather events, ecosystem disruption, agricultural challenges, and human health effects. These impacts vary regionally but collectively pose significant risks to natural and human systems.

Addressing climate change requires mitigation strategies to reduce emissions (renewable energy, efficiency improvements, carbon pricing) and adaptation measures to build resilience against unavoidable impacts, with considerations of equity and just transition.
"""
        # Conservation focus
        elif any(term in prompt_lower for term in ["biodiversity", "conservation", "species", "habitat", "wildlife", "ecosystem", "extinction"]):
            return """
Biodiversity conservation addresses the accelerating loss of species and ecosystem diversity through habitat protection, sustainable resource management, and species recovery programs. Current extinction rates far exceed background rates, constituting a sixth mass extinction event.

Protected areas, from strict nature reserves to sustainable use areas, protect approximately 17% of land and 8% of marine environments globally, though effectiveness varies. Conservation increasingly incorporates Indigenous knowledge and community-based approaches.

Beyond intrinsic value arguments, biodiversity conservation recognizes ecosystem services vital to human wellbeing, including food security, water purification, climate regulation, and cultural values, while addressing threats from development, pollution, invasive species, and climate change.
"""
        # Sustainability focus
        elif any(term in prompt_lower for term in ["sustainability", "sustainable development", "circular economy", "renewable", "green"]):
            return """
Sustainability balances environmental protection, social wellbeing, and economic development to meet present needs without compromising future generations. The UN Sustainable Development Goals provide a framework addressing poverty, inequality, climate change, environmental degradation, and justice.

Sustainable systems minimize resource depletion and pollution while maximizing efficiency and regeneration. Approaches include circular economy models (designing out waste and pollution), regenerative agriculture, renewable energy systems, and sustainable urban planning.

Implementation requires policy reform, technological innovation, business model transformation, and lifestyle changes, with ongoing debates about growth limits, technological solutions, and balancing immediate needs with long-term stewardship.
"""
        # Default environmental response
        else:
            return """
Environmental science studies interactions among physical, chemical, and biological components of natural systems and human impacts on these systems. Key concepts include ecosystem services, carrying capacity, resilience, feedback loops, and interdependence.

Current environmental challenges include climate change, biodiversity loss, pollution, resource depletion, and environmental justice concerns. These complex issues span local to global scales and require interdisciplinary approaches combining natural and social sciences.

Environmental management employs various tools including regulation, market mechanisms, education, technological innovation, and collaborative governance to balance human needs with ecosystem health and intergenerational equity.
"""

    def _get_education_fallback_response(self, prompt_lower):
        """Generate an education domain fallback response"""
        # Teaching and pedagogy
        if any(term in prompt_lower for term in ["teaching", "pedagogy", "instruction", "learning methods", "curriculum"]):
            return """
Effective teaching draws on diverse pedagogical approaches tailored to learning objectives, student characteristics, and contexts. Evidence-based practices include active learning, formative assessment, differentiated instruction, and metacognitive strategies supporting deeper understanding.

Curriculum design considers knowledge sequencing, competency development, cultural relevance, and authentic assessment. Modern approaches balance disciplinary depth with interdisciplinary connections and transferable skills development.

Digital technologies expand instructional possibilities through personalized learning paths, collaboration tools, simulation environments, and access to diverse resources, though pedagogical purpose should drive technology integration rather than novelty.
"""
        # Educational policy and systems
        elif any(term in prompt_lower for term in ["education policy", "school system", "reform", "standards", "accountability"]):
            return """
Educational systems worldwide balance centralized standards with local adaptation, traditional knowledge with innovation, and universal access with specialized pathways. Policy frameworks address curriculum standards, teacher qualifications, school funding, assessment systems, and governance structures.

Reform initiatives target various challenges including achievement gaps, workforce preparation, educational equity, and system responsiveness to changing societal needs. Evidence-informed policies consider implementation contexts and capacity building alongside desired outcomes.

Comparative education research examines how different systems address common challenges, while respecting distinctive cultural and historical contexts that shape educational values, governance approaches, and resource allocation.
"""
        # Educational technology
        elif any(term in prompt_lower for term in ["edtech", "educational technology", "online learning", "digital education", "e-learning"]):
            return """
Educational technology encompasses tools, platforms, and approaches supporting teaching and learning processes. Effective implementation balances technology capabilities with sound pedagogical principles and accessible design.

Digital learning environments range from supplemental tools to fully online programs, with various models including synchronous/asynchronous activities, self-paced modules, intelligent tutoring systems, and immersive simulations. Blended approaches often optimize benefits of both online and in-person learning.

Emerging technologies like AI, extended reality, and learning analytics offer new possibilities for personalization, engagement, and assessment, though considerations include data privacy, digital equity, and maintaining human relationships central to education.
"""
        # Default education response
        else:
            return """
Education encompasses formal and informal processes developing knowledge, skills, values, and capabilities across the lifespan. Educational approaches vary by cultural context, age group, subject domain, and purpose, from foundational literacy to specialized expertise.

Learning sciences research reveals complex cognitive, social, and emotional dimensions of learning, informing evidence-based practices that support deep understanding, skill transfer, and learner agency. Effective education balances knowledge acquisition with critical thinking, creativity, and application.

Contemporary educational challenges include accessibility, equity, relevance to changing social and economic needs, assessment systems, and adapting traditional institutions to technological and demographic shifts while maintaining core educational values.
"""

    def _create_sequential_thinking_prompt(self, problem: str, num_thoughts: int = 5) -> str:
        """
        Create a prompt for sequential thinking.
        
        Args:
            problem: The problem to solve
            num_thoughts: Target number of thoughts (may be adjusted by the model)
            
        Returns:
            str: A structured prompt for sequential thinking
        """
        return f"""I need to solve this problem using sequential thinking: {problem}

To solve this problem effectively, I'll break it down into individual thoughts, which will allow me to track my thinking process and revise as needed.

IMPORTANT INSTRUCTIONS:
1. I should use approximately {num_thoughts} thoughts to solve this, but I can adjust if needed
2. For each thought, I'll include:
   - The thought number (e.g., "Thought 1:")
   - My current thinking
   - Whether I need to revise any previous thoughts
   - Whether I need more thoughts beyond my initial estimate
3. I should explicitly address when I'm revising previous thinking
4. I should be willing to branch into alternative approaches if needed
5. After working through my thoughts, I'll provide a clear final answer

Let me think through this step-by-step:

"""
    
    def _create_sequential_list_prompt(self, problem: str, num_steps: int = 5) -> str:
        """
        Create a prompt for sequential list-based thinking (simpler structure).
        
        Args:
            problem: The problem to solve
            num_steps: Target number of steps
            
        Returns:
            str: A structured prompt for list-based sequential thinking
        """
        return f"""I need to solve this problem: {problem}

To solve this effectively, I'll break down my approach into approximately {num_steps} clear, sequential steps.

For each step, I will:
1. Think carefully about what needs to be done
2. Consider how this step builds on previous steps
3. Explain my reasoning clearly
4. Revise previous steps if I realize they need adjustment

Starting with Step 1, I'll work through this problem methodically:

"""

    def _create_cot_prompt(self, problem: str) -> str:
        """
        Create a simpler chain-of-thought prompt (alternative approach).
        
        Args:
            problem: The problem to solve
            
        Returns:
            str: A structured prompt for chain-of-thought
        """
        return f"""I need to solve this problem: {problem}

Let me work through this step-by-step:

"""

    def _create_got_prompt(self, problem: str) -> str:
        """
        Create a Graph-of-Thought prompt for non-linear problem solving.
        
        Args:
            problem: The problem to solve
            
        Returns:
            str: A structured prompt for graph-of-thought reasoning
        """
        return f"""I need to solve this problem using Graph-of-Thought reasoning: {problem}

Unlike traditional linear thinking, I'll explore multiple thought branches and connect related concepts:

THOUGHT GRAPH STRUCTURE:
- I'll identify key concepts as nodes in my thought graph
- I'll explore multiple thought branches in parallel labeled as Branch A, Branch B, etc.
- I'll create connections between related thoughts with "Connection:" labels
- I'll identify where branches converge with "Convergence:" labels
- I'll identify critical insights with "Key Insight:" labels

Let me build this thought graph to solve the problem:

"""

    async def solve_with_sequential_thinking(
        self, 
        problem: str, 
        context: Optional[Dict[str, Any]] = None,
        prompt_style: str = "sequential",
        num_thoughts: int = 5,
        temperature: float = 0.2,
        max_tokens: int = 2000,
        retry_attempts: int = 2
    ) -> Tuple[bool, str]:
        """
        Generate a solution to a problem using sequential thinking.
        
        Args:
            problem: The problem to solve
            context: Additional context dictionary to include in the prompt
            prompt_style: The thinking style to use ('sequential', 'list', 'cot', 'cov', or 'got')
            num_thoughts: Target number of thoughts in the sequential thinking output
            temperature: Temperature parameter for the LLM
            max_tokens: Maximum number of tokens to generate
            retry_attempts: Number of retries if the response validation fails
            
        Returns:
            tuple: (success_flag, response_text)
        """
        if not self.llm_provider:
            from bot_utilities.ai_utils import generate_response
            
        # Format context string for inclusion in the prompt
        context_str = "No additional context provided."
        if context:
            try:
                context_str = "Context information:\n"
                for key, value in context.items():
                    if isinstance(value, dict):
                        context_str += f"- {key}:\n"
                        for sub_key, sub_value in value.items():
                            context_str += f"  - {sub_key}: {sub_value}\n"
                    else:
                        context_str += f"- {key}: {value}\n"
            except Exception as e:
                logger.error(f"Error formatting context: {e}")
                context_str = f"Error formatting context: {str(e)}"
                
        # Choose the appropriate thinking style template
        if prompt_style not in self.thinking_style_templates:
            logger.warning(f"Unknown prompt style '{prompt_style}', defaulting to 'sequential'")
            prompt_style = "sequential"
            
        # Get the template for the chosen style
        template = self.thinking_style_templates[prompt_style]
        
        # Format the prompt with the problem and context
        try:
            prompt_template = template["prompt"]
            prompt = prompt_template.format(problem=problem, context=context_str)
        except Exception as e:
            logger.error(f"Error formatting prompt: {e}")
            return False, f"Error formatting prompt: {e}"
            
        # Get the output parser for the chosen style
        output_parser = template.get("output_parser", self._parse_sequential_output)
        
        # Keep track of attempts
        best_response = None
        best_attempt_length = 0
        
        for attempt in range(retry_attempts + 1):
            try:
                # Call the LLM with the prompt
                response = await self._call_llm(
                    prompt=prompt,
                    temperature=temperature + (0.1 * attempt),  # Slightly increase temperature with each attempt
                    max_tokens=max_tokens
                )
                
                # Store the best response by length, even if validation fails
                response_length = len(response.strip())
                if not best_response or response_length > best_attempt_length:
                    best_response = response
                    best_attempt_length = response_length
                
                # Validate the response
                is_valid = self._validate_sequential_response(response, prompt_style)
                
                if is_valid:
                    # Parse and format the response
                    parsed_response = output_parser(response)
                    return True, parsed_response
                else:
                    # Log retry attempts
                    if attempt < retry_attempts:
                        logger.warning(f"Response validation failed, retrying ({attempt+1}/{retry_attempts})")
                    else:
                        logger.error("Response validation failed after all attempts, formatting best response")
                        # Instead of just parsing, use enhanced cleaning and formatting
                        cleaned_response = self._clean_and_format_response(best_response, prompt_style)
                        return False, cleaned_response
            except Exception as e:
                logger.error(f"Error in solve_with_sequential_thinking: {str(e)}")
                if attempt < retry_attempts:
                    logger.info(f"Retrying after error ({attempt+1}/{retry_attempts})")
                    await asyncio.sleep(1)  # Brief pause before retry
                else:
                    # If we have a best response, try to format it despite the error
                    if best_response:
                        cleaned_response = self._clean_and_format_response(best_response, prompt_style)
                        return False, cleaned_response
                    return False, f"Error generating sequential thinking response after {retry_attempts} attempts: {str(e)}"
                    
        # This should not be reached, but just in case all attempts silently fail
        if best_response:
            cleaned_response = self._clean_and_format_response(best_response, prompt_style)
            return False, cleaned_response
        return False, "Failed to generate a valid response after multiple attempts."

    def _validate_sequential_response(self, response: str, prompt_style: str) -> bool:
        """
        Validate that the response follows the expected structure for the given thinking style.
        
        Args:
            response: The response to validate
            prompt_style: The thinking style used
            
        Returns:
            bool: True if the response is valid, False otherwise
        """
        # Empty or very short responses are not valid
        if not response or len(response.strip()) < 20:
            return False
            
        # For long responses with substantial content, consider them valid
        # This helps avoid unnecessary retries when the model produces good content
        # but doesn't match our exact formatting expectations
        if len(response.strip()) > 800:
            paragraphs = response.split('\n\n')
            if len(paragraphs) >= 3:
                # If it has multiple paragraphs and sufficient length, it's likely valid
                return True
        
        # Convert to lowercase for case-insensitive matching
        response_lower = response.strip().lower()
        
        # For extremely long responses with substantial content, do a quick structural check
        if len(response_lower) > 1000:
            # Check for common structural elements in longer responses
            has_paragraphs = response.count('\n\n') >= 2
            has_numbered_elements = bool(re.search(r'\n\s*\d+[\.\)]', response))
            has_conclusion_marker = any(marker in response_lower for marker in ['conclusion', 'summary', 'answer', 'therefore', 'thus', 'in summary'])
            
            if has_paragraphs and (has_numbered_elements or has_conclusion_marker):
                return True
        
        # Style-specific validation
        if prompt_style == "sequential" or prompt_style == "cot":
            # Check for clear step or thought sequence
            step_patterns = [
                r'(?:^|\n)\s*(?:step|thought|thinking|point)\s*\d+[\.\:]',  # "Step 1:", "Thought 2." etc.
                r'(?:^|\n)\s*\d+\s*[\.\)]\s+\w+',  # "1. First" or "2) Next" etc.
                r'(?:^|\n)\s*(?:first|second|third|fourth|fifth|next)\s*[\.\:\,]', # "First:" etc.
                r'(?:^|\n)\s*(?:let\'s|let me) (?:start|begin|first|break|analyze)', # "Let's start", "Let me analyze" etc.
                r'(?:^|\n)\s*(?:to solve|to approach|approaching|solving) this',  # Solving approaches
                r'(?:^|\n)\s*(?:the conflict|this conflict|the dispute|the situation|the problem)',  # Topic references
                r'(?:^|\n)\s*(?:looking at|analyzing|examining|understanding)'  # Analysis indicators
            ]
            
            has_steps = any(re.search(pattern, response_lower) for pattern in step_patterns)
            
            # Check for a conclusion or final answer
            conclusion_patterns = [
                r'(?:^|\n)\s*(?:conclusion|answer|summary|result|in conclusion)[\s\:\.]',
                r'(?:^|\n)\s*(?:in conclusion|to conclude|to summarize|in summary)',
                r'(?:^|\n)\s*(?:therefore|thus|hence|so)\s+',
                r'(?:^|\n)\s*(?:the (?:solution|answer|result) is)',
                r'(?:^|\n|\s)\s*(?:finally|ultimately|overall)\s*[\:\,\.]',
                r'(?:^|\n)\s*(?:to understand|understanding|key aspects|main factors)'
            ]
            
            has_conclusion = any(re.search(pattern, response_lower) for pattern in conclusion_patterns) or "conflict" in response_lower
            
            # For India-Pakistan conflict specifically, if it mentions relevant keywords, consider it valid
            if "india" in response_lower and "pakistan" in response_lower:
                relevant_terms = ["kashmir", "partition", "1947", "war", "nuclear", "territory", "dispute"]
                if any(term in response_lower for term in relevant_terms):
                    return True
            
            # For sequential/CoT, we need either steps or a conclusion, not necessarily both
            # This makes validation less strict
            return has_steps or has_conclusion
            
        elif prompt_style == "cov":
            # Check for verification steps
            verification_patterns = [
                r'(?:^|\n)\s*(?:verification|verify|checking|check)[\s\:\.]',
                r'(?:^|\n)\s*(?:fact.?check|validate|validation)[\s\:\.]',
                r'(?:^|\n)\s*(?:reviewing|review|double.?check)[\s\:\.]',
                r'(?:^|\n)\s*(?:confirm|confirming|ensure|ensuring)[\s\:\.]',
                r'(?:^|\n)\s*(?:let\'s verify|let me verify|i should verify)'
            ]
            
            has_verification = any(re.search(pattern, response_lower) for pattern in verification_patterns)
            
            # For CoV, just need either verification elements or regular structure
            has_basic_structure = self._validate_sequential_response(response, "sequential")
            
            return has_verification or has_basic_structure
            
        elif prompt_style == "list":
            # Check for bullet points or numbered list
            list_patterns = [
                r'(?:^|\n)\s*[\-\*\•]\s+\w+',  # Bullet points
                r'(?:^|\n)\s*\d+\s*[\.\)]\s+\w+',  # Numbered list
                r'(?:^|\n)\s*[a-z][\.\)]\s+\w+'  # Letter list
            ]
            
            # Count how many list items we find
            list_item_count = sum(len(re.findall(pattern, response)) for pattern in list_patterns)
            
            # For list style, need at least 2 list items (lowered requirement)
            return list_item_count >= 2
            
        elif prompt_style == "got":
            # Check for branches, connections or distinct thought paths
            branch_patterns = [
                r'(?:^|\n)\s*(?:branch|path|approach|perspective|angle)\s*[\w\d][\:\.]',
                r'(?:^|\n)\s*(?:alternative|option|consideration)\s*[\w\d][\:\.]',
                r'(?:^|\n)\s*(?:connection|link|relationship|related)\s*[\:\.]',
                r'(?:^|\n)\s*(?:concept|idea|thought)\s*[\d\w][\:\.]',
                r'(?:^|\n)\s*(?:from another perspective|on the other hand)'
            ]
            
            branch_count = sum(len(re.findall(pattern, response)) for pattern in branch_patterns)
            
            # For GoT, need at least one branch or check if it's a good general response
            if branch_count >= 1:
                return True
                
            # Fall back to sequential validation
            return self._validate_sequential_response(response, "sequential")
            
        # If style not recognized, validate using sequential as default
        return self._validate_sequential_response(response, "sequential")

    def _clean_and_format_response(self, response: str, prompt_style: str) -> str:
        """
        Clean and minimally format a response even if validation failed
        
        Args:
            response: Raw response
            prompt_style: The thinking style used
            
        Returns:
            str: Cleaned and formatted response
        """
        # Remove any potential preamble content
        response = re.sub(r'^.*?(?=(?:Step|STEP|Thought|THOUGHT|First|Let|To solve|I\'ll|I will))', '', response, flags=re.DOTALL|re.IGNORECASE)
        
        # Extract the main content sections
        lines = response.split('\n')
        formatted_lines = []
        current_section = None
        
        for line in lines:
            # Detect section headers and format them
            if re.match(r'^\s*(?:step|thought|thinking|point)\s*\d+[\.\:]', line.lower()):
                match = re.match(r'^\s*(?:step|thought|thinking|point)\s*(\d+)[\.\:]', line.lower())
                if match:
                    num = match.group(1)
                    content = re.sub(r'^\s*(?:step|thought|thinking|point)\s*\d+[\.\:]\s*', '', line, flags=re.IGNORECASE)
                    formatted_lines.append(f"**Step {num}**: {content}")
                    current_section = "step"
                else:
                    formatted_lines.append(line)
            elif re.match(r'^\s*\d+\s*[\.\)]\s+', line):
                match = re.match(r'^\s*(\d+)\s*[\.\)]\s+', line)
                if match:
                    num = match.group(1)
                    content = re.sub(r'^\s*\d+\s*[\.\)]\s+', '', line)
                    formatted_lines.append(f"**Step {num}**: {content}")
                    current_section = "step"
                else:
                    formatted_lines.append(line)
            elif re.match(r'^\s*(?:conclusion|answer|summary|result|in conclusion)[\s\:\.]', line.lower()):
                content = re.sub(r'^\s*(?:conclusion|answer|summary|result|in conclusion)[\s\:\.\,]\s*', '', line, flags=re.IGNORECASE)
                formatted_lines.append(f"**Conclusion**: {content}")
                current_section = "conclusion"
            elif re.match(r'^\s*(?:verification|validation|check)[\s\:\.]', line.lower()):
                content = re.sub(r'^\s*(?:verification|validation|check)[\s\:\.\,]\s*', '', line, flags=re.IGNORECASE)
                formatted_lines.append(f"**Verification**: {content}")
                current_section = "verification"
            elif line.strip() == "":
                # Preserve empty lines
                formatted_lines.append("")
            elif current_section:
                # Content belonging to a section
                formatted_lines.append(line)
            else:
                # General content
                formatted_lines.append(line)
        
        # Join the formatted lines
        formatted_text = "\n".join(formatted_lines)
        
        # Ensure there's a conclusion if we didn't find one
        if "**Conclusion**" not in formatted_text:
            last_paragraphs = formatted_text.split("\n\n")[-2:]
            for i, para in enumerate(last_paragraphs):
                if "therefore" in para.lower() or "thus" in para.lower() or "hence" in para.lower() or "in summary" in para.lower():
                    last_paragraphs[i] = f"**Conclusion**: {para}"
                    break
            else:
                # If no conclusion indicators found, just label the last paragraph
                if len(last_paragraphs) > 0:
                    last_paragraphs[-1] = f"**Conclusion**: {last_paragraphs[-1]}"
            
            # Replace the last paragraphs in the text
            if len(last_paragraphs) > 0:
                formatted_text = formatted_text.rsplit("\n\n", len(last_paragraphs))[0] + "\n\n" + "\n\n".join(last_paragraphs)
        
        return formatted_text.strip()

    async def run(self, problem, context=None, prompt_style="sequential", num_thoughts=5, 
               temperature=0.7, max_tokens=2000, timeout=60):
        """
        Run sequential thinking process on a problem
        
        Args:
            problem: The problem/query to analyze
            context: Optional context dictionary with additional information
            prompt_style: Type of thinking to use ("sequential", "cot", "got", "cov")
            num_thoughts: Target number of thoughts
            temperature: Temperature setting for randomness
            max_tokens: Maximum tokens to generate
            timeout: Timeout in seconds
            
        Returns:
            tuple: (success_flag, formatted_response)
        """
        if context is None:
            context = {}
        
        # Normalize prompt style
        prompt_style = prompt_style.lower()
        
        try:
            # Select the appropriate prompt based on thinking style
            if prompt_style == "cot" or prompt_style == "chain-of-thought":
                prompt = self._create_cot_prompt(problem)
            elif prompt_style == "got" or prompt_style == "graph-of-thought":
                prompt = self._create_got_prompt(problem, num_thoughts)
            elif prompt_style == "cov" or prompt_style == "chain-of-verification":
                prompt = self._create_cov_prompt(problem)
            else:
                # Default to sequential thinking
                prompt = self._create_sequential_thinking_prompt(problem, num_thoughts)
            
            # Add context if available
            enhanced_prompt = self._add_context_to_prompt(prompt, context)
            
            # Call the language model with a timeout
            try:
                response = await self._call_llm(
                    prompt=enhanced_prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=timeout
                )
                
                # Format the response based on the thinking type
                if prompt_style == "cot" or prompt_style == "chain-of-thought":
                    formatted_response = self._parse_cot_output(response)
                elif prompt_style == "got" or prompt_style == "graph-of-thought":
                    formatted_response = self._parse_got_output(response)
                elif prompt_style == "cov" or prompt_style == "chain-of-verification":
                    formatted_response = self._parse_cov_output(response)
                else:
                    # Default to sequential parsing
                    formatted_response = self._parse_sequential_output(response)
                
                # If parsing failed or the response is too short, return the raw response
                if not formatted_response or len(formatted_response) < 20:
                    # Basic cleaning and return the raw response
                    clean_response = response.replace("AI:", "").replace("Assistant:", "").strip()
                    return True, clean_response
                    
                return True, formatted_response
                
            except Exception as e:
                print(f"Error in SequentialThinking.run: {e}")
                
                # Try fallback to simpler approach with reduced parameters
                try:
                    # Simplify the prompt
                    fallback_prompt = f"""Please help me solve this problem step by step:
                    
                    {problem}
                    
                    Think carefully and break down your reasoning."""
                    
                    fallback_response = await self._call_llm(
                        prompt=fallback_prompt,
                        temperature=0.3,  # Lower temp for more reliable response
                        max_tokens=max_tokens,
                        timeout=30  # Shorter timeout for fallback
                    )
                    
                    # Simplified parsing - just remove any system instructions
                    clean_response = fallback_response.replace("AI:", "").replace("Assistant:", "").strip()
                    clean_response = re.sub(r'^\s*instructions?:.*?\n', '', clean_response, flags=re.IGNORECASE|re.DOTALL)
                    
                    return True, clean_response
                    
                except Exception as fallback_e:
                    print(f"Fallback also failed: {fallback_e}")
                    
                    # As a last resort, use domain-specific fallback
                    domain_response = self._get_domain_specific_fallback(problem.lower())
                    return False, domain_response
                    
        except Exception as outer_e:
            print(f"Critical error in SequentialThinking.run: {outer_e}")
            # Ultimate fallback
            fallback = f"""I apologize, but I'm having difficulty processing this complex problem. 

Here's what I can suggest:

1. Try breaking down your question into smaller, more specific parts
2. Provide more context or background information
3. Specify what aspect of the problem you'd like me to focus on first

I'm here to help, so feel free to rephrase or simplify your question."""
            
            return False, fallback

    async def _detect_problem_type(self, problem: str) -> str:
        """
        Automatically detect what type of reasoning would be best for the problem.
        
        Args:
            problem: The problem to analyze
            
        Returns:
            str: The recommended reasoning style
        """
        problem_lower = problem.lower()
        
        # Keywords that suggest factual verification would be helpful
        factual_keywords = [
            "fact", "accurate", "truth", "verify", "correct", "accuracy", 
            "precise", "exact", "valid", "check", "confirm", "evidence",
            "proof", "source", "citation", "reference", "statistic", 
            "data", "figure", "number", "percentage", "rate", "date",
            "historical", "scientific", "research", "study", "analysis",
            "report", "survey", "poll", "census", "experiment", "finding",
            "discovery", "publication", "paper", "journal", "article",
            "news", "event", "incident", "occurrence", "phenomenon",
            "development", "trend", "pattern", "movement", "shift"
        ]
        
        # Keywords that suggest complex, multifaceted thinking
        complex_keywords = [
            "complex", "complicated", "intricate", "multifaceted", "nuanced",
            "sophisticated", "advanced", "detailed", "elaborate", "involved",
            "compare", "contrast", "analyze", "different angles", "perspectives",
            "approaches", "alternatives", "options", "possibilities", "considerations",
            "factors", "variables", "parameters", "dimensions", "aspects",
            "elements", "components", "branches", "connections", "relationships",
            "links", "networks", "systems", "structures", "frameworks",
            "models", "theories", "concepts", "ideas", "principles",
            "philosophies", "ideologies", "doctrines", "schools of thought"
        ]
        
        # Check if the problem contains factual keywords
        needs_verification = any(keyword in problem_lower for keyword in factual_keywords)
        
        # Check if the problem is complex
        is_complex = any(keyword in problem_lower for keyword in complex_keywords)
        
        # Check if it's a multi-step problem
        is_multi_step = (
            "step" in problem_lower or
            "process" in problem_lower or
            "procedure" in problem_lower or
            "sequence" in problem_lower or
            "chain" in problem_lower or
            "progression" in problem_lower or
            "workflow" in problem_lower
        )
        
        # Check if it's likely a creative problem
        is_creative = (
            "create" in problem_lower or
            "design" in problem_lower or
            "develop" in problem_lower or
            "innovate" in problem_lower or
            "imagine" in problem_lower or
            "brainstorm" in problem_lower or
            "generate" in problem_lower or
            "invent" in problem_lower or
            "craft" in problem_lower or
            "compose" in problem_lower or
            "author" in problem_lower or
            "write" in problem_lower
        )
        
        # Decision logic for the most appropriate style
        if needs_verification:
            return "cov"  # Chain of Verification for factual problems
        elif is_complex and not is_multi_step:
            return "got"  # Graph of Thought for complex, interconnected problems
        elif is_multi_step and not is_creative:
            return "sequential"  # Sequential for procedural problems
        elif is_creative:
            return "list"  # List for creative ideation
        else:
            return "cot"  # Chain of Thought as the default for general reasoning

    def _parse_sequential_output(self, output: str) -> str:
        """
        Parse sequential thinking output
        
        Args:
            output: Raw LLM output
            
        Returns:
            str: Formatted output for display
        """
        # Process output and format with Markdown for Discord
        formatted_output = ""
        
        # Extract thoughts using regex
        thoughts_pattern = re.compile(r'(?:Thought|THOUGHT|Step|STEP)\s*(\d+)[:\)\.]\s*(.*?)(?=(?:Thought|THOUGHT|Step|STEP)\s*\d+[:\)\.]\s*|Conclusion|CONCLUSION|$)', re.DOTALL)
        conclusion_pattern = re.compile(r'(?:Conclusion|CONCLUSION)[:\)\.]\s*(.*)', re.DOTALL)
        
        # Extract thoughts
        thoughts = thoughts_pattern.findall(output)
        
        # If no thoughts are found with the pattern, just return the original output
        # But clean it from internal markers first
        if not thoughts:
            # Clean response by removing internal markers/debugging information
            clean_output = self.format_response(output)
            clean_output = re.sub(r'Contains explicit sequential indicator:.*?(?=\n|$)', '', clean_output)
            clean_output = re.sub(r'Sequential thinking recommended.*?(?=\n|$)', '', clean_output)
            clean_output = re.sub(r'Complexity indicators:.*?(?=\n|$)', '', clean_output)
            clean_output = re.sub(r'Topic indicators:.*?(?=\n|$)', '', clean_output)
            clean_output = re.sub(r'General complexity.*?(?=\n|$)', '', clean_output)
            return clean_output
            
        # Format thoughts (only include 1-2 steps for brevity unless they're short)
        total_steps = len(thoughts)
        should_include_all = total_steps <= 3 or sum(len(thought) for _, thought in thoughts) < 800
        
        if should_include_all:
            # Include all steps
            for num, thought in thoughts:
                formatted_output += f"{thought.strip()}\n\n"
        else:
            # Too many steps, include intro and conclusion steps
            if total_steps > 0:
                num, thought = thoughts[0]  # First step
                formatted_output += f"{thought.strip()}\n\n"
                
            if total_steps > 2:
                formatted_output += f"*... (analyzing in {total_steps-2} more steps) ...*\n\n"
                
            if total_steps > 1:
                num, thought = thoughts[-1]  # Last step
                formatted_output += f"{thought.strip()}\n\n"
        
        # Extract conclusion
        conclusion_match = conclusion_pattern.search(output)
        if conclusion_match:
            conclusion = conclusion_match.group(1).strip()
            formatted_output += f"{conclusion}\n"
        else:
            # If no explicit conclusion, use last paragraph as conclusion
            paragraphs = output.split('\n\n')
            if paragraphs:
                last_paragraph = paragraphs[-1].strip()
                if "thought" not in last_paragraph.lower() and "step" not in last_paragraph.lower():
                    formatted_output += f"{last_paragraph}\n"
        
        # Clean the formatted output by removing any debugging information
        formatted_output = re.sub(r'Contains explicit sequential indicator:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Sequential thinking recommended.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Complexity indicators:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Topic indicators:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'General complexity.*?(?=\n|$)', '', formatted_output)
        
        return formatted_output
    
    def _parse_list_output(self, output: str) -> str:
        """
        Parse list-based thinking output
        
        Args:
            output: Raw LLM output
            
        Returns:
            str: Formatted output for display
        """
        # Format with Markdown for Discord
        formatted_output = ""
        
        # Split into lines for processing
        lines = output.split('\n')
        bullet_pattern = re.compile(r'^\s*[-•*]\s*(.*)')
        conclusion_pattern = re.compile(r'(?:Conclusion|CONCLUSION|Summary|SUMMARY)[:\)\.]\s*(.*)', re.DOTALL)
        
        # Process bullet points
        point_number = 1
        in_bullet_section = False
        processed_lines = []
        
        for line in lines:
            bullet_match = bullet_pattern.match(line)
            if bullet_match:
                in_bullet_section = True
                point_text = bullet_match.group(1).strip()
                processed_lines.append(f"{point_text}")
                point_number += 1
            elif in_bullet_section and line.strip() == "":
                processed_lines.append("")  # Preserve empty lines
            elif in_bullet_section and line.strip():
                # This is continuation text for the previous bullet
                processed_lines[-1] += " " + line.strip()
            else:
                processed_lines.append(line)
        
        # Combine processed lines
        formatted_output = "\n".join(processed_lines)
        
        # Extract conclusion
        conclusion_match = conclusion_pattern.search(output)
        if conclusion_match:
            conclusion = conclusion_match.group(1).strip()
            
            # Check if conclusion is already in formatted_output
            if f"{conclusion}" not in formatted_output:
                formatted_output += f"\n\n{conclusion}"
        
        # Clean the formatted output by removing any debugging information
        formatted_output = re.sub(r'Contains explicit sequential indicator:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Sequential thinking recommended.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Complexity indicators:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'Topic indicators:.*?(?=\n|$)', '', formatted_output)
        formatted_output = re.sub(r'General complexity.*?(?=\n|$)', '', formatted_output)
        
        return formatted_output
    
    def _parse_cot_output(self, output: str) -> str:
        """
        Parse chain-of-thought output
        
        Args:
            output: Raw LLM output
            
        Returns:
            str: Formatted output for display
        """
        # Clean any debugging or internal markers
        clean_output = re.sub(r'Contains explicit sequential indicator:.*?(?=\n|$)', '', output)
        clean_output = re.sub(r'Sequential thinking recommended.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'Complexity indicators:.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'Topic indicators:.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'General complexity.*?(?=\n|$)', '', clean_output)
        
        # Extract the final answer or conclusion for a cleaner output
        conclusion_pattern = re.compile(r'(?:Conclusion|CONCLUSION|Finally|In conclusion|Therefore|Thus|Hence)[:\)\.]?\s*(.*?)$', re.DOTALL)
        conclusion_match = conclusion_pattern.search(clean_output)
        
        if conclusion_match:
            # Found a clear conclusion, return just that
            conclusion = conclusion_match.group(1).strip()
            return conclusion
        else:
            # Extract the final paragraph as the answer if no explicit conclusion
            paragraphs = clean_output.split('\n\n')
            if paragraphs:
                return paragraphs[-1].strip()
            else:
                return clean_output.strip()
    
    def _parse_cov_output(self, output: str) -> str:
        """
        Parse chain-of-verification output
        
        Args:
            output: Raw LLM output
            
        Returns:
            str: Formatted output for display
        """
        # Clean any debugging or internal markers
        clean_output = re.sub(r'Contains explicit sequential indicator:.*?(?=\n|$)', '', output)
        clean_output = re.sub(r'Sequential thinking recommended.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'Complexity indicators:.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'Topic indicators:.*?(?=\n|$)', '', clean_output)
        clean_output = re.sub(r'General complexity.*?(?=\n|$)', '', clean_output)
        
        # Extract steps and verifications using regex patterns
        steps_pattern = re.compile(r'(?:Step|STEP)\s*(\d+)[:\)\.]\s*(.*?)(?=(?:Verification|VERIFICATION|Step|STEP)\s*\d+[:\)\.]\s*|Conclusion|CONCLUSION|$)', re.DOTALL)
        verifications_pattern = re.compile(r'(?:Verification|VERIFICATION)\s*(\d+)[:\)\.]\s*(.*?)(?=(?:Step|STEP|Verification|VERIFICATION)\s*\d+[:\)\.]\s*|Conclusion|CONCLUSION|$)', re.DOTALL)
        conclusion_pattern = re.compile(r'(?:Conclusion|CONCLUSION|Final Answer|FINAL ANSWER)[:\)\.]\s*(.*)', re.DOTALL)
        
        # Extract steps and verifications
        steps = steps_pattern.findall(clean_output)
        verifications = verifications_pattern.findall(clean_output)
        
        # If no structured content is found, fall back to sequential parsing
        if not steps and not verifications:
            return self._parse_sequential_output(output)
        
        # Create a combined ordered list of steps and verifications
        combined_elements = []
        
        # Add steps to the combined list
        for num, content in steps:
            combined_elements.append(("step", int(num), content.strip()))
            
        # Add verifications to the combined list
        for num, content in verifications:
            combined_elements.append(("verification", int(num), content.strip()))
        
        # Sort by number and then type (steps before verifications)
        combined_elements.sort(key=lambda x: (x[1], 0 if x[0] == "step" else 1))
        
        # Format combined elements
        for element_type, num, content in combined_elements:
            if element_type == "step":
                formatted_output += f"**Step {num}**: {content}\n\n"
            else:
                formatted_output += f"**Verification {num}**: {content}\n\n"
        
        # Extract conclusion
        conclusion_match = conclusion_pattern.search(clean_output)
        if conclusion_match:
            conclusion = conclusion_match.group(1).strip()
            formatted_output += f"**Final Verified Answer**: {conclusion}\n"
        else:
            # If no explicit conclusion, use last paragraph as conclusion
            paragraphs = clean_output.split('\n\n')
            if paragraphs:
                last_paragraph = paragraphs[-1].strip()
                if "step" not in last_paragraph.lower() and "verification" not in last_paragraph.lower():
                    formatted_output += f"**Final Verified Answer**: {last_paragraph}\n"
        
        return formatted_output
    
    def _parse_got_output(self, output: str) -> str:
        """
        Parse Graph-of-Thought output into a more readable format
        
        Args:
            output: Raw LLM output
            
        Returns:
            str: Formatted output for display
        """
        # Start with a clean output
        formatted = ""
        
        # Extract thinking branches
        branch_pattern = re.compile(r'Branch\s+(\w+)[:\)\.]\s*(.*?)(?=Branch\s+\w+[:\)\.]|Convergence|Conclusion|$)', re.DOTALL | re.IGNORECASE)
        branches = branch_pattern.findall(output)
        
        # Extract convergence/conclusion
        conclusion_pattern = re.compile(r'(?:Convergence|Conclusion)[:\)\.]\s*(.*?)$', re.DOTALL | re.IGNORECASE)
        conclusion_match = conclusion_pattern.search(output)
        conclusion = conclusion_match.group(1).strip() if conclusion_match else ""
        
        # Parse branch connections
        connection_pattern = re.compile(r'Connection[:\)\.]\s*(.*?)(?=Branch|Connection|Convergence|Conclusion|$)', re.DOTALL | re.IGNORECASE)
        connections = connection_pattern.findall(output)
        
        # If we found structured graph elements, format them
        if branches or conclusion:
            # Process branches
            if branches:
                formatted += "**Key Insights:**\n\n"
                for branch_id, branch_content in branches:
                    formatted += f"**{branch_id}**: {branch_content.strip()}\n\n"
            
            # Process connections if found
            if connections:
                formatted += "**Connections:**\n\n"
                for connection in connections:
                    formatted += f"- {connection.strip()}\n"
                formatted += "\n"
            
            # Add conclusion
            if conclusion:
                formatted += f"**Conclusion:**\n\n{conclusion}\n"
        else:
            # Fallback to extracting any bullet points if structured format isn't found
            bullet_pattern = re.compile(r'(?:^|\n)[\-\*•]\s*(.*?)(?=$|\n[\-\*•])', re.DOTALL)
            bullets = bullet_pattern.findall(output)
            
            if bullets:
                formatted += "**Key Points:**\n\n"
                for bullet in bullets:
                    formatted += f"• {bullet.strip()}\n\n"
            else:
                # Last resort: return the original text with minimal cleaning
                return self._clean_text(output)
        
        return formatted.strip()
        
    async def _create_got_prompt(self, problem: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Create a prompt for Graph-of-Thought reasoning
        
        Args:
            problem: The problem to solve
            context: Optional context dictionary
            
        Returns:
            str: A structured prompt for GoT
        """
        # Extract relevant context
        username = context.get("username", "User") if context else "User"
        
        got_prompt = f"""I need to solve this problem using Graph-of-Thought reasoning: {problem}

To solve this effectively, I'll use a non-linear Graph-of-Thought approach where I explore multiple parallel conceptual branches and their interconnections.

APPROACH:
1. I'll identify multiple conceptual branches relevant to the problem
2. For each branch, I'll explore key ideas, facts, and considerations 
3. I'll identify connections between different branches
4. I'll converge the branches to form a comprehensive solution

BRANCHES: (label each as Branch A, Branch B, etc.)
- Branch A should focus on the core problem definition and key elements
- Branch B should explore relevant contexts, background, and assumptions
- Branch C should examine potential solutions, approaches, or interpretations
- Additional branches as needed for specific domain knowledge

CONNECTIONS: (explicitly note how branches relate to each other)
- Identify relationships between ideas across different branches
- Note dependencies, conflicts, or supporting evidence between branches

CONVERGENCE:
- Synthesize insights from all branches 
- Integrate connections to form a coherent answer
- Present the final solution derived from this graph-based exploration

Please format your response with clear "Branch" labels, "Connection" sections between relevant branches, and a final "Conclusion" that provides the answer.
"""

        # Add specific context if available
        if context:
            history = context.get("history", [])
            if history:
                got_prompt += "\n\nRecent conversation context:"
                for msg in history[-3:]:  # Add last 3 exchanges for context
                    role = msg.get("role", "").title()
                    content = msg.get("content", "")
                    got_prompt += f"\n{role}: {content}"
            
            # Add any enhanced context from context manager
            enhanced_context = context.get("enhanced_context", {})
            if enhanced_context:
                got_prompt += "\n\nAdditional context to consider:"
                if "relevant_thinking" in enhanced_context:
                    got_prompt += "\nRelevant past thinking:"
                    for thinking in enhanced_context["relevant_thinking"][:2]:  # Limit to 2 most relevant
                        got_prompt += f"\n- {thinking.get('problem', '')}: {thinking.get('solution', '')[:100]}..."
                
                if "conversation_topic" in enhanced_context:
                    got_prompt += f"\nCurrent conversation topic: {enhanced_context['conversation_topic']}"
        
        got_prompt += f"""

Now, please solve the problem for {username} using this Graph-of-Thought approach, exploring multiple branches of reasoning and their interconnections before converging on a comprehensive answer.
"""
        return got_prompt
        
    async def solve_with_graph_thinking(
        self, 
        problem: str, 
        context: Optional[Dict[str, Any]] = None,
        temperature: float = 0.5,
        max_tokens: int = 2000,
        timeout: int = 60
    ) -> Tuple[bool, str]:
        """
        Solve a problem using Graph-of-Thought reasoning
        
        Args:
            problem: The problem to solve
            context: Additional context dictionary
            temperature: Temperature setting for randomness
            max_tokens: Maximum tokens to generate
            timeout: Timeout in seconds
            
        Returns:
            Tuple[bool, str]: Success flag and response
        """
        # Build the complete Graph-of-Thought prompt
        got_prompt = await self._create_got_prompt(problem, context)
        
        # Make the LLM call with appropriate parameters
        try:
            response = await self._call_llm(
                prompt=got_prompt,
                temperature=temperature,
                max_tokens=max_tokens,
                timeout=timeout,
                include_thinking=True
            )
            
            # Check if we got a valid response
            if not response or len(response.strip()) < 20:
                return False, await get_fallback_response(problem)
                
            # Parse and format the Graph-of-Thought output
            formatted_response = self._parse_got_output(response)
            
            # Record successful response for potential caching
            record_llm_success()
            cache_successful_response(problem, formatted_response)
            
            return True, formatted_response
            
        except Exception as e:
            print(f"Error in Graph-of-Thought reasoning: {e}")
            return False, await get_fallback_response(problem)
            
    async def run(self, problem, context=None, prompt_style="sequential", num_thoughts=5, 
               temperature=0.7, max_tokens=2000, timeout=60):
        """
        Run sequential thinking process on a problem
        
        Args:
            problem: The problem/query to analyze
            context: Optional context dictionary with additional information
            prompt_style: Type of thinking to use ("sequential", "cot", "got", "cov")
            num_thoughts: Target number of thoughts
            temperature: Temperature setting for randomness
            max_tokens: Maximum tokens to generate
            timeout: Timeout in seconds
            
        Returns:
            Tuple[bool, str]: (success flag, response string)
        """
        # Determine the most appropriate thinking approach based on problem
        if prompt_style == "auto":
            prompt_style = await self._detect_problem_type(problem)
            print(f"Auto-selected thinking style: {prompt_style}")
        
        if prompt_style == "sequential":
            return await self.solve_with_sequential_thinking(
                problem=problem,
                context=context,
                num_thoughts=num_thoughts,
                temperature=temperature,
                max_tokens=max_tokens
            )
        elif prompt_style == "list":
            # Use list-based thinking for this problem
            prompt = self._create_sequential_list_prompt(problem, num_steps=num_thoughts)
            
            try:
                response = await self._call_llm(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=timeout,
                    include_thinking=True
                )
                
                # Parse and format response
                parsed_response = self._parse_list_output(response)
                
                return True, parsed_response
            except Exception as e:
                return False, f"Error in list thinking: {str(e)}"
        elif prompt_style == "cot":
            # Use chain-of-thought reasoning
            prompt = self._create_cot_prompt(problem)
            
            try:
                response = await self._call_llm(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=timeout,
                    include_thinking=True
                )
                
                # Parse and format response
                parsed_response = self._parse_cot_output(response)
                
                return True, parsed_response
            except Exception as e:
                return False, f"Error in chain-of-thought: {str(e)}"
        elif prompt_style == "got":
            # Use graph-of-thought reasoning
            return await self.solve_with_graph_thinking(
                problem=problem,
                context=context,
                temperature=temperature,
                max_tokens=max_tokens,
                timeout=timeout
            )
        elif prompt_style == "cov":
            # Use chain-of-verification reasoning
            prompt = self._create_cov_prompt(problem)
            
            try:
                response = await self._call_llm(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=timeout,
                    include_thinking=True
                )
                
                # Parse and format response
                parsed_response = self._parse_cov_output(response)
                
                return True, parsed_response
            except Exception as e:
                return False, f"Error in chain-of-verification: {str(e)}"
        else:
            # Default to sequential thinking
            return await self.solve_with_sequential_thinking(
                problem=problem,
                context=context,
                num_thoughts=num_thoughts,
                temperature=temperature,
                max_tokens=max_tokens
            )
```
""" 