"""
Agent Orchestrator

This module coordinates the execution of specialized reasoning agents,
manages agent transitions, and maintains conversation context.
"""

import asyncio
import logging
import json
import re
from typing import Dict, List, Any, Optional, Callable, Tuple, Set

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('agent_orchestrator')

class AgentOrchestrator:
    """
    Orchestrates the selection and execution of different reasoning agents
    based on user queries and context.
    """
    
    def __init__(self, llm_provider=None, tools_manager=None):
        """
        Initialize the orchestrator with required components
        
        Args:
            llm_provider: Provider for language model capabilities
            tools_manager: Manager for agent tools
        """
        self.llm_provider = llm_provider
        self.tools_manager = tools_manager
        self.conversation_memories = {}  # Maps conversation_id to history
        self.agent_configs = {}  # Maps agent_type to configuration
        self.user_preferences = {}  # Maps user_id to preferences
        
        # Load agent configurations
        self._load_agent_configs()
    
    def _load_agent_configs(self):
        """Load agent configurations from file or defaults"""
        try:
            # Try to load from a config file if it exists
            with open("configs/agent_configs.yaml", "r") as f:
                import yaml
                self.agent_configs = yaml.safe_load(f)
        except (FileNotFoundError, ImportError):
            # Use default configurations
            self.agent_configs = {
                "conversational": {
                    "description": "Natural, friendly conversation with context awareness",
                    "emoji": "ðŸ’¬",
                    "tools": ["search", "calculator", "memory"],
                },
                "rag": {
                    "description": "Information retrieval and fact-based responses with sources",
                    "emoji": "ðŸ“š",
                    "tools": ["search", "web", "memory", "knowledge_base"],
                },
                "sequential": {
                    "description": "Step-by-step logical reasoning for complex problems",
                    "emoji": "ðŸ”„",
                    "tools": ["calculator", "memory", "code_execution"],
                },
                "verification": {
                    "description": "Fact-checking and verification of information",
                    "emoji": "âœ…",
                    "tools": ["search", "web", "knowledge_base", "fact_checker"],
                },
                "creative": {
                    "description": "Creative writing, storytelling, and idea generation",
                    "emoji": "ðŸŽ¨",
                    "tools": ["memory", "image_generation"],
                },
                "calculation": {
                    "description": "Mathematical calculations and numerical analysis",
                    "emoji": "ðŸ§®",
                    "tools": ["calculator", "code_execution", "symbolic_math"],
                },
                "graph": {
                    "description": "Network and relationship analysis",
                    "emoji": "ðŸ“Š",
                    "tools": ["graph_analyzer", "memory", "visualization"],
                },
                "multi_agent": {
                    "description": "Multiple specialized agents working together",
                    "emoji": "ðŸ‘¥",
                    "tools": ["agent_delegation", "memory"],
                },
            }
            logger.info("Using default agent configurations")
    
    async def process_query(
        self,
        query: str,
        conversation_id: str,
        user_id: str,
        reasoning_type: str = "conversational",
        max_steps: int = 5,
        update_callback: Optional[Callable[[str, Dict[str, Any]], None]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Process a user query with the appropriate agent(s)
        
        Args:
            query: The user's query
            conversation_id: ID for the conversation
            user_id: ID of the user
            reasoning_type: Primary reasoning type to use
            max_steps: Maximum number of reasoning steps
            update_callback: Optional callback for status updates
            context: Additional context information
            
        Returns:
            The response generated by the agent(s)
        """
        # Ensure conversation memory exists
        if conversation_id not in self.conversation_memories:
            self.conversation_memories[conversation_id] = []
            
        # Store the current query in history
        self.conversation_memories[conversation_id].append({
            "role": "user",
            "content": query,
            "user_id": user_id,
            "timestamp": self._get_timestamp()
        })
        
        # Prepare context for the agent
        agent_context = {
            "conversation_id": conversation_id,
            "user_id": user_id,
            "history": self.conversation_memories[conversation_id],
            "preferences": self.user_preferences.get(user_id, {}),
        }
        
        # Add any additional context
        if context:
            agent_context.update(context)
            
        # Track steps for multi-step reasoning
        steps = 0
        current_reasoning_type = reasoning_type
        interim_results = []
        
        while steps < max_steps:
            # Notify about the current reasoning type
            if update_callback:
                await update_callback("agent_switch", {
                    "agent_type": current_reasoning_type,
                    "step": steps + 1
                })
                
            # Get the agent configuration
            agent_config = self.agent_configs.get(
                current_reasoning_type, 
                self.agent_configs.get("conversational")
            )
            
            # Build the system prompt for this agent type
            system_prompt = self._build_system_prompt(current_reasoning_type, agent_config)
            
            # Run thinking/reasoning step with the LLM
            thinking = await self._run_thinking_step(
                query, 
                agent_context, 
                current_reasoning_type,
                system_prompt
            )
            
            # Share thinking with callback if provided
            if update_callback:
                await update_callback("thinking", {
                    "thinking": thinking,
                    "step": steps + 1
                })
                
            # Determine if we need to use any tools
            tool_calls = self._extract_tool_calls(thinking)
            
            if tool_calls and self.tools_manager:
                # Execute the tool calls
                for tool_call in tool_calls:
                    tool_name = tool_call.get("name", "")
                    tool_args = tool_call.get("arguments", {})
                    
                    # Notify about tool usage
                    if update_callback:
                        await update_callback("tool_use", {
                            "tool_name": tool_name,
                            "args": tool_args
                        })
                    
                    # Execute the tool and get results
                    try:
                        tool_result = await self.tools_manager.execute_tool(
                            tool_name, 
                            tool_args,
                            context=agent_context
                        )
                        
                        # Add the tool result to interim results
                        interim_results.append({
                            "type": "tool_result",
                            "tool": tool_name,
                            "result": tool_result
                        })
                        
                    except Exception as e:
                        logger.error(f"Error executing tool {tool_name}: {str(e)}")
                        interim_results.append({
                            "type": "tool_error",
                            "tool": tool_name,
                            "error": str(e)
                        })
            
            # Add the thinking to interim results
            interim_results.append({
                "type": "thinking",
                "reasoning_type": current_reasoning_type,
                "content": thinking
            })
            
            # Check if we need to switch reasoning types
            next_reasoning_type = self._determine_next_reasoning(
                thinking, 
                current_reasoning_type,
                interim_results
            )
            
            if next_reasoning_type != current_reasoning_type:
                # Reasoning type switch needed
                if update_callback:
                    await update_callback("reasoning_switch", {
                        "from_type": current_reasoning_type,
                        "to_type": next_reasoning_type,
                        "reason": "Reasoning type transition based on analysis"
                    })
                    
                current_reasoning_type = next_reasoning_type
                
                # Continue to next iteration with new reasoning type
                steps += 1
                continue
            
            # Generate the final response for this reasoning path
            response = await self._generate_response(
                query,
                agent_context,
                current_reasoning_type,
                interim_results,
                system_prompt
            )
            
            # Store the response in conversation history
            self.conversation_memories[conversation_id].append({
                "role": "assistant",
                "content": response,
                "reasoning_type": current_reasoning_type,
                "timestamp": self._get_timestamp()
            })
            
            # Return the response
            return response
            
        # If we reached max steps without a conclusion
        return "I apologize, but I wasn't able to reach a conclusive answer within the allowed reasoning steps. Please try rephrasing your question or breaking it into smaller parts."
    
    async def _run_thinking_step(
        self, 
        query: str, 
        context: Dict[str, Any], 
        reasoning_type: str,
        system_prompt: str
    ) -> str:
        """
        Run a thinking/reasoning step with the AI
        
        Args:
            query: The query to reason about
            context: Contextual information
            reasoning_type: The reasoning type to use
            system_prompt: System prompt for the AI
            
        Returns:
            Thinking/reasoning result as text
        """
        if not self.llm_provider:
            return "Thinking step not available (LLM provider not configured)."
            
        # Create a thinking prompt that encourages step-by-step reasoning
        thinking_prompt = f"""
        [Thinking Step for {reasoning_type} reasoning]
        
        Question: {query}
        
        Think through this step-by-step, considering:
        1. What information is needed?
        2. What approaches could work?
        3. What are potential concerns or limitations?
        
        Relevant context:
        {self._format_context(context)}
        """
        
        # Call the LLM to generate thinking
        try:
            # Create the messages format expected by generate_text
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": thinking_prompt}
            ]
            
            response = await self.llm_provider.generate_text(
                messages=messages,
                temperature=0.7,  # Slightly creative for exploration
                max_tokens=1000   # Allow for detailed reasoning
            )
            return response
        except Exception as e:
            logger.error(f"Error in thinking step: {str(e)}")
            return "Error in thinking process."
    
    async def _generate_response(
        self,
        query: str,
        context: Dict[str, Any],
        reasoning_type: str,
        interim_results: List[Dict[str, Any]],
        system_prompt: str
    ) -> str:
        """
        Generate a final response based on reasoning and interim results
        
        Args:
            query: Original user query
            context: Context information
            reasoning_type: Current reasoning type
            interim_results: Results from reasoning and tool usage
            system_prompt: System prompt for the AI
            
        Returns:
            Final response to the user
        """
        if not self.llm_provider:
            return "Response generation not available (LLM provider not configured)."
            
        # Format interim results into context
        interim_context = ""
        for result in interim_results:
            if result["type"] == "thinking":
                interim_context += f"\n\n[Reasoning: {result['reasoning_type']}]\n{result['content']}"
            elif result["type"] == "tool_result":
                interim_context += f"\n\n[Tool Result: {result['tool']}]\n{result['result']}"
            elif result["type"] == "tool_error":
                interim_context += f"\n\n[Tool Error: {result['tool']}]\n{result['error']}"
        
        # Build the response prompt
        response_prompt = f"""
        [Final Response Generation for {reasoning_type} reasoning]
        
        Original Question: {query}
        
        Based on the following reasoning and information, provide a clear, helpful response:
        {interim_context}
        
        Additional context:
        {self._format_context(context)}
        
        Important: 
        1. Be concise yet thorough
        2. Address all aspects of the original question
        3. Use the appropriate tone for {reasoning_type} reasoning
        4. If using information from tools, incorporate it naturally
        """
        
        try:
            # Create the messages format expected by generate_text
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": response_prompt}
            ]
            
            # Generate the final response
            response = await self.llm_provider.generate_text(
                messages=messages,
                temperature=0.5,  # More focused for final response
                max_tokens=1000   # Allow for detailed response
            )
            
            # Add the appropriate emoji for the reasoning type
            emoji = self.agent_configs.get(reasoning_type, {}).get("emoji", "")
            if emoji and not response.startswith(emoji):
                response = f"{emoji} {response}"
                
            return response
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            return "I apologize, but I encountered an error while generating a response."
    
    def _build_system_prompt(self, reasoning_type: str, agent_config: Dict[str, Any]) -> str:
        """
        Build a system prompt for a specific reasoning type
        
        Args:
            reasoning_type: The reasoning type
            agent_config: Configuration for this agent type
            
        Returns:
            System prompt for the LLM
        """
        description = agent_config.get("description", "")
        
        # Default system prompt template
        system_prompt = f"""
        You are an AI assistant specialized in {reasoning_type} reasoning.
        
        {description}
        
        When providing answers:
        - Use a step-by-step approach when appropriate
        - Clearly identify facts versus opinions
        - If you encounter uncertainty, acknowledge the limitations
        - Support your reasoning with evidence when possible
        """
        
        # Add reasoning-specific instructions
        if reasoning_type == "rag":
            system_prompt += """
            For retrieval-augmented generation:
            - Always cite sources when providing factual information
            - Distinguish clearly between retrieved information and inferences
            - When uncertain, indicate the confidence level of your answers
            - Present the most relevant information first
            """
        elif reasoning_type == "sequential":
            system_prompt += """
            For sequential reasoning:
            - Break down complex problems into clear steps
            - Number each step in your reasoning
            - Explain the connection between steps
            - Show interim conclusions at each stage
            """
        elif reasoning_type == "verification":
            system_prompt += """
            For verification reasoning:
            - Evaluate claims based on evidence
            - Consider multiple perspectives
            - Check for logical consistency
            - Clearly state whether claims are supported, refuted, or uncertain
            """
        elif reasoning_type == "creative":
            system_prompt += """
            For creative reasoning:
            - Generate original and imaginative ideas
            - Consider unconventional approaches
            - Use vivid language and examples
            - Embrace divergent thinking
            """
        elif reasoning_type == "calculation":
            system_prompt += """
            For calculation reasoning:
            - Show mathematical steps clearly
            - Use precise notation
            - Verify calculations when possible
            - Consider the practical meaning of numerical results
            """
        elif reasoning_type == "graph":
            system_prompt += """
            For graph reasoning:
            - Identify relationships between entities
            - Analyze connection patterns
            - Consider indirect relationships
            - Describe the overall structure of networks
            """
        elif reasoning_type == "multi_agent":
            system_prompt += """
            For multi-agent reasoning:
            - Present multiple perspectives
            - Consider each perspective's strengths and limitations
            - Synthesize insights from different viewpoints
            - Acknowledge competing valid interpretations
            """
            
        return system_prompt
    
    def _format_context(self, context: Dict[str, Any]) -> str:
        """Format context information for inclusion in prompts"""
        formatted = []
        
        # Add conversation history if available
        if "history" in context and context["history"]:
            history = context["history"]
            # Only use the last few messages to keep context manageable
            recent_history = history[-5:] if len(history) > 5 else history
            
            formatted.append("Recent conversation:")
            for msg in recent_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role and content:
                    formatted.append(f"- {role.capitalize()}: {content}")
        
        # Add user preferences if available
        if "preferences" in context and context["preferences"]:
            prefs = context["preferences"]
            formatted.append("User preferences:")
            for key, value in prefs.items():
                formatted.append(f"- {key}: {value}")
                
        # Add any other context information
        for key, value in context.items():
            if key not in ["history", "preferences"] and value:
                if isinstance(value, dict):
                    formatted.append(f"{key.capitalize()}:")
                    for k, v in value.items():
                        formatted.append(f"- {k}: {v}")
                elif isinstance(value, list):
                    formatted.append(f"{key.capitalize()}: {', '.join(str(item) for item in value)}")
                else:
                    formatted.append(f"{key.capitalize()}: {value}")
                    
        return "\n".join(formatted)
    
    def _extract_tool_calls(self, thinking: str) -> List[Dict[str, Any]]:
        """
        Extract tool calls from the thinking text
        
        Args:
            thinking: The thinking/reasoning text
            
        Returns:
            List of tool calls as dictionaries
        """
        tool_calls = []
        
        # Look for tool call patterns in the thinking text
        # Example pattern: "Use tool: <tool_name>(<args>)"
        tool_pattern = r"Use tool:\s+([a-zA-Z0-9_]+)\(([^)]*)\)"
        matches = re.finditer(tool_pattern, thinking, re.MULTILINE)
        
        for match in matches:
            tool_name = match.group(1)
            args_str = match.group(2)
            
            # Parse arguments
            args = {}
            if args_str:
                # Handle simple key=value arguments
                arg_pairs = args_str.split(",")
                for pair in arg_pairs:
                    if "=" in pair:
                        key, value = pair.split("=", 1)
                        args[key.strip()] = value.strip()
            
            tool_calls.append({
                "name": tool_name,
                "arguments": args
            })
            
        # Also look for JSON-formatted tool calls
        json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
        for match in re.finditer(json_pattern, thinking):
            try:
                tool_json = json.loads(match.group(0))
                if "tool" in tool_json and "args" in tool_json:
                    tool_calls.append({
                        "name": tool_json["tool"],
                        "arguments": tool_json["args"]
                    })
            except json.JSONDecodeError:
                pass
                
        return tool_calls
    
    def _determine_next_reasoning(
        self, 
        thinking: str, 
        current_reasoning_type: str,
        interim_results: List[Dict[str, Any]]
    ) -> str:
        """
        Determine if a reasoning type switch is needed
        
        Args:
            thinking: Current thinking text
            current_reasoning_type: Current reasoning type
            interim_results: Results so far
            
        Returns:
            Next reasoning type to use (might be the same)
        """
        # By default, continue with the same reasoning
        next_reasoning_type = current_reasoning_type
        
        # Check for explicit switch signals in the thinking
        switch_patterns = {
            "rag": ["need to search", "requires research", "let's look up", "need more information"],
            "sequential": ["break this down step by step", "analyze systematically", "solve step by step"],
            "verification": ["need to verify", "fact check", "confirm this information"],
            "creative": ["generate ideas", "creative solution", "think outside the box"],
            "calculation": ["calculate", "compute", "mathematical analysis"],
            "graph": ["map the relationships", "network analysis", "connection pattern"],
            "multi_agent": ["consider different perspectives", "multiple viewpoints", "collaborative approach"]
        }
        
        # Check thinking text for switch indicators
        lower_thinking = thinking.lower()
        
        for reasoning_type, patterns in switch_patterns.items():
            if reasoning_type != current_reasoning_type:  # Only consider switches to different types
                if any(pattern in lower_thinking for pattern in patterns):
                    return reasoning_type
        
        # Check for tool usage patterns that suggest a reasoning type
        tool_reasoning_map = {
            "search": "rag",
            "web": "rag",
            "knowledge_base": "rag",
            "calculator": "calculation",
            "code_execution": "sequential",
            "graph_analyzer": "graph",
            "fact_checker": "verification"
        }
        
        # Check if recent tool usage suggests a reasoning switch
        for result in reversed(interim_results):
            if result["type"] == "tool_result" and "tool" in result:
                tool_name = result["tool"]
                if tool_name in tool_reasoning_map and tool_reasoning_map[tool_name] != current_reasoning_type:
                    return tool_reasoning_map[tool_name]
                    
        # No switch needed
        return next_reasoning_type
    
    def _get_timestamp(self) -> str:
        """Get the current timestamp"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    async def reset_conversation(self, conversation_id: str) -> None:
        """
        Reset a conversation
        
        Args:
            conversation_id: The conversation to reset
        """
        if conversation_id in self.conversation_memories:
            self.conversation_memories[conversation_id] = []
            logger.info(f"Reset conversation {conversation_id}")
    
    async def clear_user_data(self, user_id: str) -> None:
        """
        Clear all data for a user
        
        Args:
            user_id: The user whose data to clear
        """
        # Clear conversation history
        for conv_id in list(self.conversation_memories.keys()):
            self.conversation_memories[conv_id] = [
                msg for msg in self.conversation_memories[conv_id] 
                if msg.get("user_id") != user_id
            ]
            
        # Clear user preferences
        if user_id in self.user_preferences:
            del self.user_preferences[user_id]
            
        logger.info(f"Cleared data for user {user_id}") 